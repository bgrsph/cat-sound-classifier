{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c5a177",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "\n",
    "Train the CatMeowCNN model on preprocessed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47341d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "sys.path.insert(0, str(Path(\"../src\").resolve()))\n",
    "\n",
    "from src.data_loader import load_train_data, load_test_data, get_train_val_loaders, get_test_loader\n",
    "from src.train import train, cross_validate\n",
    "from src.test import test\n",
    "from src.transforms import SpecAugment, Compose, RandomApply, AddNoise\n",
    "from models import CatMeowCNN, TransferCNN\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e1fd9",
   "metadata": {},
   "source": [
    "## 1. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d00502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(80, 128, 173), y=(80,)\n",
      "Test:  X=(20, 128, 173), y=(20,)\n",
      "Classes: 10\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/interim\")\n",
    "MODEL_PATH = Path(\"../results/cat_meow.pt\")\n",
    "\n",
    "# Ensure results dir exists\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load train and test separately\n",
    "X_train, y_train = load_train_data(DATA_DIR)\n",
    "X_test, y_test = load_test_data(DATA_DIR)\n",
    "\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test:  X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"Classes: {len(set(y_train))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd904d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 64 samples (with augmentation)\n",
      "Val: 16 samples\n",
      "Test: 20 samples (held out)\n"
     ]
    }
   ],
   "source": [
    "# Augmentation for training\n",
    "train_transform = Compose([\n",
    "    SpecAugment(freq_mask_param=15, time_mask_param=25),\n",
    "    RandomApply(AddNoise(noise_level=0.005), p=0.3),\n",
    "])\n",
    "\n",
    "# Split training data into train/val\n",
    "train_loader, val_loader = get_train_val_loaders(\n",
    "    X_train, y_train, batch_size=16, train_transform=train_transform\n",
    ")\n",
    "print(f\"Train: {len(train_loader.dataset)} samples (with augmentation)\")\n",
    "print(f\"Val: {len(val_loader.dataset)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples (held out)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2e5bd",
   "metadata": {},
   "source": [
    "## 2. Create Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548ecbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CatMeowCNN\n",
      "Parameters: 422,986\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(set(y_train))\n",
    "model = CatMeowCNN(n_classes=n_classes)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: CatMeowCNN\")\n",
    "print(f\"Parameters: {n_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4b8d1",
   "metadata": {},
   "source": [
    "## 3. Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b78e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a final model and evaluate on test set\n",
    "model = CatMeowCNN(n_classes=n_classes)\n",
    "\n",
    "# Get fresh loaders\n",
    "train_loader, val_loader = get_train_val_loaders(\n",
    "    X_train, y_train, batch_size=16, train_transform=train_transform\n",
    ")\n",
    "\n",
    "history = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    save_path=str(MODEL_PATH),\n",
    "    patience=40,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be03c6",
   "metadata": {},
   "source": [
    "## 5. Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate on held-out test data\n",
    "model.load_state_dict(torch.load(MODEL_PATH, weights_only=True))\n",
    "test_loader = get_test_loader(X_test, y_test)\n",
    "results = test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f617a6",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation\n",
    "\n",
    "Run k-fold cross-validation for a more reliable accuracy estimate with limited data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 5-fold cross-validation on training data\n",
    "cv_results = cross_validate(\n",
    "    model_class=CatMeowCNN,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    n_splits=5,\n",
    "    epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=16,\n",
    "    patience=40,\n",
    "    n_classes=n_classes,  # passed to CatMeowCNN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e80321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "folds = [r[\"fold\"] for r in cv_results[\"fold_results\"]]\n",
    "accs = cv_results[\"accuracies\"]\n",
    "\n",
    "ax.bar(folds, accs, color='steelblue', edgecolor='white')\n",
    "ax.axhline(cv_results[\"mean_acc\"], color='red', linestyle='--', \n",
    "           label=f'Mean: {cv_results[\"mean_acc\"]:.3f} ¬± {cv_results[\"std_acc\"]:.3f}')\n",
    "ax.set_xlabel(\"Fold\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"5-Fold Cross-Validation Results\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCV Accuracy: {cv_results['mean_acc']:.1%} ¬± {cv_results['std_acc']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves for each fold\n",
    "n_folds = len(cv_results[\"fold_results\"])\n",
    "fig, axes = plt.subplots(n_folds, 2, figsize=(12, 3 * n_folds))\n",
    "\n",
    "for i, fold_result in enumerate(cv_results[\"fold_results\"]):\n",
    "    fold_history = fold_result[\"history\"]\n",
    "    fold_num = fold_result[\"fold\"]\n",
    "    \n",
    "    # Loss\n",
    "    axes[i, 0].plot(fold_history[\"train_loss\"], label=\"Train\")\n",
    "    axes[i, 0].plot(fold_history[\"val_loss\"], label=\"Val\")\n",
    "    axes[i, 0].set_xlabel(\"Epoch\")\n",
    "    axes[i, 0].set_ylabel(\"Loss\")\n",
    "    axes[i, 0].set_title(f\"Fold {fold_num} - Loss\")\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[i, 1].plot(fold_history[\"train_acc\"], label=\"Train\")\n",
    "    axes[i, 1].plot(fold_history[\"val_acc\"], label=\"Val\")\n",
    "    axes[i, 1].set_xlabel(\"Epoch\")\n",
    "    axes[i, 1].set_ylabel(\"Accuracy\")\n",
    "    axes[i, 1].set_title(f\"Fold {fold_num} - Accuracy (Best: {fold_result['best_val_acc']:.3f})\")\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0acbf",
   "metadata": {},
   "source": [
    "## 8. Save Results for Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all training results for diagnostics notebook\n",
    "import pickle\n",
    "\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Bundle all results\n",
    "training_results = {\n",
    "    \"history\": history,\n",
    "    \"cv_results\": cv_results,\n",
    "    \"test_results\": results,\n",
    "    \"n_classes\": n_classes,\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / \"training_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_results, f)\n",
    "\n",
    "print(f\"Saved training results to {RESULTS_DIR / 'training_results.pkl'}\")\n",
    "print(f\"  - Training history: {len(history['train_loss'])} epochs\")\n",
    "print(f\"  - CV results: {len(cv_results['fold_results'])} folds\")\n",
    "print(f\"  - Test accuracy: {results['accuracy']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e3792",
   "metadata": {},
   "source": [
    "## 9. Model Comparison: CNN vs Transfer Learning\n",
    "\n",
    "Compare our simple CatMeowCNN with transfer learning using pretrained ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TransferCNN\n",
    "\n",
    "# Define models to compare\n",
    "models_to_compare = {\n",
    "    \"CatMeowCNN\": lambda: CatMeowCNN(n_classes=n_classes),\n",
    "    \"TransferCNN (frozen)\": lambda: TransferCNN(n_classes=n_classes, backbone=\"resnet18\", freeze_backbone=True),\n",
    "    \"TransferCNN (fine-tune)\": lambda: TransferCNN(n_classes=n_classes, backbone=\"resnet18\", freeze_backbone=False),\n",
    "}\n",
    "\n",
    "# Show model sizes\n",
    "print(\"Model Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "for name, model_fn in models_to_compare.items():\n",
    "    m = model_fn()\n",
    "    total = sum(p.numel() for p in m.parameters())\n",
    "    trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "    print(f\"{name:25} | Total: {total:>10,} | Trainable: {trainable:>10,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation for each model\n",
    "comparison_results = {}\n",
    "\n",
    "for name, model_fn in models_to_compare.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Use lower learning rate for transfer learning\n",
    "    lr = 0.0001 if \"Transfer\" in name else 0.001\n",
    "    \n",
    "    cv_result = cross_validate(\n",
    "        model_class=model_fn,  # Pass the lambda function\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        n_splits=5,\n",
    "        epochs=50,  # Fewer epochs for comparison\n",
    "        learning_rate=lr,\n",
    "        batch_size=16,\n",
    "        patience=15,\n",
    "        n_classes=n_classes,\n",
    "        verbose=False,  # Less output\n",
    "    )\n",
    "    \n",
    "    comparison_results[name] = cv_result\n",
    "    print(f\"\\n‚úì {name}: {cv_result['mean_acc']:.1%} ¬± {cv_result['std_acc']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison results\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "model_names = list(comparison_results.keys())\n",
    "means = [comparison_results[name][\"mean_acc\"] for name in model_names]\n",
    "stds = [comparison_results[name][\"std_acc\"] for name in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(x, means, yerr=stds, capsize=10, color=colors, \n",
    "              edgecolor='white', linewidth=2, error_kw={'linewidth': 2})\n",
    "\n",
    "ax.set_xlabel(\"Model\", fontsize=12)\n",
    "ax.set_ylabel(\"CV Accuracy\", fontsize=12)\n",
    "ax.set_title(\"Model Comparison (5-Fold Cross-Validation)\", fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='Random baseline')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.03,\n",
    "            f'{mean:.1%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for name in model_names:\n",
    "    r = comparison_results[name]\n",
    "    print(f\"{name:25} | {r['mean_acc']:.1%} ¬± {r['std_acc']:.1%}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find best model\n",
    "best_model = max(comparison_results.keys(), key=lambda k: comparison_results[k]['mean_acc'])\n",
    "print(f\"\\nüèÜ Best Model: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aeae7",
   "metadata": {},
   "source": [
    "### Train Best Model on Full Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da63525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model on full training data\n",
    "BEST_MODEL_PATH = Path(\"../results/best_model.pt\")\n",
    "\n",
    "# Use TransferCNN with frozen backbone (usually best for small data)\n",
    "best_model = TransferCNN(n_classes=n_classes, backbone=\"resnet18\", freeze_backbone=True)\n",
    "\n",
    "# Get fresh loaders\n",
    "train_loader, val_loader = get_train_val_loaders(\n",
    "    X_train, y_train, batch_size=16, train_transform=train_transform\n",
    ")\n",
    "\n",
    "print(f\"Training best model: TransferCNN (frozen ResNet18)\")\n",
    "print(f\"Trainable params: {sum(p.numel() for p in best_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "best_history = train(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=100,\n",
    "    learning_rate=0.0001,  # Lower LR for transfer learning\n",
    "    save_path=str(BEST_MODEL_PATH),\n",
    "    patience=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f86e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model on test set\n",
    "best_model.load_state_dict(torch.load(BEST_MODEL_PATH, weights_only=True))\n",
    "test_loader = get_test_loader(X_test, y_test)\n",
    "best_results = test(best_model, test_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"CatMeowCNN Test Accuracy:    {results['accuracy']:.1%}\")\n",
    "print(f\"TransferCNN Test Accuracy:   {best_results['accuracy']:.1%}\")\n",
    "print(f\"Improvement:                 {(best_results['accuracy'] - results['accuracy'])*100:+.1f} percentage points\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da5343",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter Optimization (Bayesian)\n",
    "\n",
    "Using Optuna with TPE sampler to find optimal hyperparameters.\n",
    "\n",
    "TPE: https://arxiv.org/abs/2304.11127\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95558535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function defined. Ready to optimize!\n",
      "Search space: model, lr, batch_size, optimizer, weight_decay, dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bugrasipahioglu/repo/cat-sound-classifier/venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Suppress Optuna logs (optional)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Optuna optimization.\"\"\"\n",
    "    \n",
    "    # Hyperparameters to tune\n",
    "    model_type = trial.suggest_categorical(\"model\", [\"CatMeowCNN\", \"TransferCNN\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "    \n",
    "    # Optimizer and regularization\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.3, 0.7)\n",
    "    \n",
    "    # Model-specific params\n",
    "    if model_type == \"TransferCNN\":\n",
    "        freeze = trial.suggest_categorical(\"freeze_backbone\", [True, False])\n",
    "        backbone = trial.suggest_categorical(\"backbone\", [\"resnet18\", \"resnet34\"])\n",
    "        model_fn = lambda: TransferCNN(\n",
    "            n_classes=n_classes, \n",
    "            backbone=backbone, \n",
    "            freeze_backbone=freeze,\n",
    "            dropout=dropout\n",
    "        )\n",
    "    else:\n",
    "        model_fn = lambda: CatMeowCNN(n_classes=n_classes, dropout=dropout)\n",
    "    \n",
    "    # Quick 3-fold CV (faster than 5-fold for tuning)\n",
    "    try:\n",
    "        cv_result = cross_validate(\n",
    "            model_class=model_fn,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            n_splits=3,\n",
    "            epochs=100,  # Full training\n",
    "            learning_rate=lr,\n",
    "            batch_size=batch_size,\n",
    "            patience=30,  # More patience for convergence\n",
    "            n_classes=n_classes,\n",
    "            verbose=False,\n",
    "            optimizer_type=optimizer_type,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "        return cv_result[\"mean_acc\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "print(\"Objective function defined. Ready to optimize!\")\n",
    "print(\"Search space: model, lr, batch_size, optimizer, weight_decay, dropout\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef267632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian Optimization with 1 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.311016: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:17<00:00, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: 31.1% | {'model': 'TransferCNN', 'lr': 0.001570297088405539, 'batch_size': 8, 'optimizer': 'sgd', 'weight_decay': 0.00025378155082656634, 'dropout': 0.5832290311184182, 'freeze_backbone': False, 'backbone': 'resnet18'}\n",
      "\n",
      "============================================================\n",
      "üéâ OPTIMIZATION COMPLETE!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian optimization\n",
    "\n",
    "N_TRIALS = 1  # Reduce for faster testing, increase for better results\n",
    "\n",
    "print(f\"Starting Bayesian Optimization with {N_TRIALS} trials...\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",  # Maximize accuracy\n",
    "    sampler=TPESampler(seed=42),\n",
    "    study_name=\"cat_mood_classifier\"\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=N_TRIALS, \n",
    "    show_progress_bar=True,\n",
    "    callbacks=[lambda study, trial: print(f\"  Trial {trial.number}: {trial.value:.1%} | {trial.params}\")]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best results\n",
    "print(f\"Best CV Accuracy: {study.best_value:.1%}\")\n",
    "print(f\"\\nBest Hyperparameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Show top 5 trials\n",
    "print(\"\\nTop 5 Trials:\")\n",
    "print(\"-\" * 60)\n",
    "trials_df = study.trials_dataframe().sort_values(\"value\", ascending=False).head(5)\n",
    "for i, row in trials_df.iterrows():\n",
    "    print(f\"  {row['value']:.1%} | model={row.get('params_model', 'N/A')}, lr={row.get('params_lr', 0):.2e}, batch={row.get('params_batch_size', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optimization history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Optimization history\n",
    "trials = [t.number for t in study.trials]\n",
    "values = [t.value for t in study.trials]\n",
    "best_so_far = [max(values[:i+1]) for i in range(len(values))]\n",
    "\n",
    "axes[0].scatter(trials, values, alpha=0.6, label=\"Trial accuracy\")\n",
    "axes[0].plot(trials, best_so_far, 'r-', linewidth=2, label=\"Best so far\")\n",
    "axes[0].set_xlabel(\"Trial\")\n",
    "axes[0].set_ylabel(\"CV Accuracy\")\n",
    "axes[0].set_title(\"Optimization History\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Parameter importance (simplified)\n",
    "param_counts = {}\n",
    "for t in study.trials:\n",
    "    if t.value >= study.best_value * 0.95:  # Top 5% trials\n",
    "        for k, v in t.params.items():\n",
    "            key = f\"{k}={v}\"\n",
    "            param_counts[key] = param_counts.get(key, 0) + 1\n",
    "\n",
    "if param_counts:\n",
    "    sorted_params = sorted(param_counts.items(), key=lambda x: -x[1])[:10]\n",
    "    params, counts = zip(*sorted_params)\n",
    "    axes[1].barh(range(len(params)), counts, color='steelblue')\n",
    "    axes[1].set_yticks(range(len(params)))\n",
    "    axes[1].set_yticklabels(params)\n",
    "    axes[1].set_xlabel(\"Count in top trials\")\n",
    "    axes[1].set_title(\"Common Parameters in Best Trials\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8cb8e5",
   "metadata": {},
   "source": [
    "### Train Final Model with Best Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best hyperparameters\n",
    "TUNED_MODEL_PATH = Path(\"../results/tuned_model.pt\")\n",
    "\n",
    "best = study.best_params\n",
    "print(f\"Training final model with best params:\")\n",
    "for k, v in best.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "# Create model based on best params\n",
    "if best[\"model\"] == \"TransferCNN\":\n",
    "    final_model = TransferCNN(\n",
    "        n_classes=n_classes, \n",
    "        backbone=best.get(\"backbone\", \"resnet18\"),\n",
    "        freeze_backbone=best.get(\"freeze_backbone\", True),\n",
    "        dropout=best.get(\"dropout\", 0.5)\n",
    "    )\n",
    "else:\n",
    "    final_model = CatMeowCNN(n_classes=n_classes, dropout=best.get(\"dropout\", 0.5))\n",
    "\n",
    "trainable = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel: {best['model']}\")\n",
    "print(f\"Trainable params: {trainable:,}\")\n",
    "\n",
    "# Get fresh loaders with best batch size\n",
    "train_loader, val_loader = get_train_val_loaders(\n",
    "    X_train, y_train, \n",
    "    batch_size=best[\"batch_size\"], \n",
    "    train_transform=train_transform\n",
    ")\n",
    "\n",
    "# Train with more epochs now, using best optimizer and regularization\n",
    "tuned_history = train(\n",
    "    model=final_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=100,\n",
    "    learning_rate=best[\"lr\"],\n",
    "    save_path=str(TUNED_MODEL_PATH),\n",
    "    patience=50,  # Match tuning patience\n",
    "    optimizer_type=best.get(\"optimizer\", \"adam\"),\n",
    "    weight_decay=best.get(\"weight_decay\", 0.0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "final_model.load_state_dict(torch.load(TUNED_MODEL_PATH, weights_only=True))\n",
    "test_loader = get_test_loader(X_test, y_test)\n",
    "tuned_results = test(final_model, test_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best CV Accuracy (during tuning): {study.best_value:.1%}\")\n",
    "print(f\"Test Accuracy (tuned model):      {tuned_results['accuracy']:.1%}\")\n",
    "print(f\"Test Loss:                        {tuned_results['loss']:.4f}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest hyperparameters saved. Model saved to: {TUNED_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tuning results for diagnostics notebook\n",
    "tuning_results = {\n",
    "    \"tuned_history\": tuned_history,\n",
    "    \"tuned_results\": tuned_results,\n",
    "    \"best_params\": study.best_params,\n",
    "    \"best_cv_acc\": study.best_value,\n",
    "    \"n_classes\": n_classes,\n",
    "    \"optimization_history\": [\n",
    "        {\"trial\": t.number, \"value\": t.value, \"params\": t.params}\n",
    "        for t in study.trials if t.value is not None\n",
    "    ],\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / \"tuning_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuning_results, f)\n",
    "\n",
    "print(f\"Saved tuning results to {RESULTS_DIR / 'tuning_results.pkl'}\")\n",
    "print(f\"  - Training history: {len(tuned_history['train_loss'])} epochs\")\n",
    "print(f\"  - Best CV accuracy: {study.best_value:.1%}\")\n",
    "print(f\"  - Test accuracy: {tuned_results['accuracy']:.1%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
